# -*- coding: utf-8 -*-
"""Nicolás Iturriaga_Proyecto M7_ Oscares

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Id0FgPwZHPBKyLcxH5pFUVgVM802q60O

## **Bootcamp: Ciencia de Datos e Inteligencia Artificial**
## **Proyecto del Módulo 7: Técnicas avanzadas para ciencia de datos y empleabilidad**

Hola, ya es el último proyecto, has avanzado y aprendido mucho hasta acá. ¡Muchas felicidades!

Es hora de poner en práctica todo lo que hemos aprendido a lo largo de nuestra travesía.

Lee el proyecto y revisa con cuidado cada una de las instrucciones. Procura plasmar todo tu potencial para que lo concluyas de manera sobresaliente.

¡Éxito!

# Objetivos
- Aplicar con éxito todos los conocimientos que has adquirido a lo largo del Bootcamp.
- Consolidar las técnicas de limpieza, entrenamiento, graficación y ajuste a modelos de *Machine Learning*.
- Generar una API que brinde predicciones como resultado a partir de datos enviados.

# Proyecto

1. Selecciona uno de los siguientes *datasets*:
  - Imágenes de rayos X de pecho para detectar neumonía: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia
  - *Reviews* de aplicaciones de la Google Play Store: https://www.kaggle.com/datasets/lava18/google-play-store-apps
  - Estadísticas demográficas de los ganadores del premio Oscar de la Academia: https://www.kaggle.com/datasets/fmejia21/demographics-of-academy-awards-oscars-winners
  - Aspiraciones profesionales de la generación Z: https://www.kaggle.com/datasets/kulturehire/understanding-career-aspirations-of-genz

Cada uno representa un *dataset*, un problema y una forma diferente de abordarlo. Tu tarea es identificar las técnicas y modelos que podrías usar para tu proyecto.

2. Debes hacer un análisis exploratorio y limpieza de los datos. Usa las ténicas que creas convenientes.

3. Entrena el modelo de *Machine Learning*, procesamiento de lenguaje natural o red neuronal que creas adecuado.

4. Genera por lo menos dos gráficas y dos métricas de rendimiento; explica las puntuaciones de rendimiento que amerite tu problema. Todas las gráficas de rendimiento que realices deben tener leyendas, colores y títulos personalizados por ti.

  - Además, antes de subir el modelo a "producción", deberás realizar un proceso de ensambles (*ensemblings*) y de ajuste de hiperparámetros o *tuning* para intentar mejorar la precisión y disminuir la varianza de tu modelo.

5. Construye una API REST en la que cualquier usuario pueda mandar datos y que esta misma devuelva la predicción del modelo que has hecho. La API debe estar en la nube, ya sea en un servicio como Netlify o Ngrok, para que pueda ser consultada desde internet.

6. Genera una presentación del problema y del modelo de solución que planteas. Muestra gráficas, datos de rendimiento y explicaciones. Esta presentación debe estar enfocada a personas que no sepan mucho de ciencia de datos e inteligencia artificial.

7. **Solamente se recibirán trabajos subidos a tu cuenta de GitHub con un README.md apropiado que explique tu proyecto**.

## Criterios de evaluación

| Actividad | Porcentaje | Observaciones | Punto parcial
| -- | -- | -- | -- |
| Actividad 1. Limpieza y EDA | 20 | Realiza todas las tareas necesarias para hacer el EDA y la limpieza correcta, dependiendo de la problemática. Debes hacer como mínimo el análisis de completitud, escalamiento (si aplica) y tokenización (si aplica). | Realizaste solo algunas tareas de exploración y limpieza y el modelo se muestra aún con oportunidad de completitud, escalamiento y/o mejora. |
| Actividad 2. Entrenamiento del modelo | 20 | Elige el modelo y algoritmo adecuados para tu problema, entrénalo con los datos ya limpios y genera algunas predicciones de prueba. | No has realizado predicciones de prueba para tu modelo de ML y/o tu modelo muestra una precisión menor al 60 %. |
| Actividad 3. Graficación y métricas | 20 | Genera por lo menos dos gráficas y dos muestras de métricas que permitan visualizar el rendimiento y precisión del modelo que construiste. Además, realizaste los procesos de *tuning* y ensambles adecuados para tu problema. | Las gráficas no tienen leyendas y colores customizados, solo muestras una gráfica o no realizaste el *tuning* de hiperparámetros.
| Actividad 4. API REST | 20 | Generaste con éxito un *link* público en el que, por método POST, se puede mandar información y la API REST devuelve una predicción junto con el porcentaje de confianza de esta misma. | N/A
| Actividad 5. Presentación | 20 | Genera una presentación en la que establezcas como mínimo: el problema, proceso de solución, metodologías usadas, gráficas de rendimiento, demostración del modelo y aprendizajes obtenidos. Debes redactarla con términos que pueda entender cualquier persona, no solo científicos de datos. | La presentación no expone con claridad o en términos coloquiales el proceso de creación del modelo, sus ventajas y muestras de rendimiento.

**Mucho éxito en tu camino como Data Scientist.**
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd

import seaborn as sns
import nltk as nltk
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from nltk.stem import WordNetLemmatizer
from nltk import download
from sklearn.model_selection import train_test_split

df = pd.read_csv('/content/drive/MyDrive/datasets_bootcamp/Oscars-demographics-DFE.csv', encoding='latin-1')
df.head()

df.head()

"""Análisis Exploratorio y Limpieza de datos.
Exploración inicial:
"""

df.info()

df.describe()

#verificamos la completitud
completitud = pd.DataFrame(df.isnull().sum())

completitud.reset_index(inplace = True)
completitud = completitud.rename(columns = {"index":"columna",0:"total"})
completitud["completitud"] = (1 - completitud["total"] / df.shape[0]) * 100
completitud = completitud.sort_values(by = "completitud", ascending = True)
completitud.reset_index(drop = True, inplace = True)

completitud

print(f'Porcentaje de completitud: {df.count().sum()/ df.size*100:.2f}%')

plt.figure(figsize=(8, 6))
df['race_ethnicity'].value_counts().sort_index().plot(kind='bar', color='skyblue')
plt.xlabel('Etnias')
plt.ylabel('Frecuencia')
plt.title('Frecuencia de Etnias')
plt.grid(axis='y')
plt.show()

plt.figure(figsize=(8, 6))
df['religion'].value_counts().sort_index().plot(kind='bar', color='skyblue')
plt.xlabel('Religiones')
plt.ylabel('Frecuencia')
plt.title('Frecuencia de ganadores por religión')
plt.grid(axis='y')
plt.show()

"""**Entrenando el modelo**

Preprocesamiento de texto
"""

#Normalización
from sklearn.preprocessing import MinMaxScaler

columnas_a_normalizar = ['religion', 'race_ethnicity']

scaler = MinMaxScaler

"""Vectorizando"""

df.head()

from sklearn.feature_extraction.text import TfidfVectorizer

cols = df['religion']

texto = cols.astype(str)

tfidf_vectorizer = TfidfVectorizer(max_features=10000)

texto_vectorizado = tfidf_vectorizer.fit_transform(texto)

texto_vectorizado_df1 = pd.DataFrame(texto_vectorizado.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

y = texto_vectorizado_df1
print(y.head())

from sklearn.feature_extraction.text import TfidfVectorizer

cols2 = df['race_ethnicity']

texto = cols2.astype(str)

tfidf_vectorizer = TfidfVectorizer(max_features=10000)

texto_vectorizado = tfidf_vectorizer.fit_transform(texto)

texto_vectorizado_df = pd.DataFrame(texto_vectorizado.toarray(), columns=tfidf_vectorizer.get_feature_names_out())

X = texto_vectorizado_df
print(X.head())

X

nombres_cols = {'asian': '0', 'black': '1', 'eastern': '2', 'hispanic': '3', 'middle': '4', 'multiracial': '5', 'white': '6'}

X = X.rename(columns=nombres_cols)

"""Modelando"""

from sklearn.preprocessing import OneHotEncoder

labels = X

encoder = OneHotEncoder(sparse=False)

X = encoder.fit_transform(np.array(labels).reshape(-1, 1))

print(X)

labels2 = y

encoder = OneHotEncoder(sparse=False)

y = encoder.fit_transform(np.array(labels2).reshape(-1, 1))

print(y)

print(len(y))
print(len(X))
#Existe una diferencia de muestras en las dos variables.

#Eliminaré los datos extras para tener un conjunto de datos más pequeño.

y = y[:len(X)]

print(len(y))
print(len(X))
#Se ajustó la cantidad de datos

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

#utilizaré modelos de clasificación con Random Forest
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicio el calificador
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train, y_train)

# predicciones
y_pred = rf_classifier.predict(X_test)

# Evalúo modelo
accuracy = accuracy_score(y_test, y_pred)
print(f'Precisión del modelo: {accuracy}')

# Reporte de clasificación
print(classification_report(y_test, y_pred))

print(len(y_test))
print(len(X_test))
print(len(y_pred))

"""Gráficos de rendimiento y métricas para el modelo"""

y_true = y

if isinstance(y_pred, np.ndarray):
    if y_pred.ndim == 2:
        print("y_pred es una matriz bidimensional.")
    else:
        print("y_pred no es una matriz bidimensional.")
else:
    print("y_pred no es un array de NumPy.")

num_classes = len(np.unique(y_true))
print(f"Número de clases en el problema: {num_classes}")
n_classes = num_classes

print(len(X_test))
print(len(y_test))

from sklearn.metrics import accuracy_score

# Calcular la precisión del modelo
accuracy = accuracy_score(y_test, y_pred)
print(f'Precisión del modelo: {accuracy:.2f}')

from sklearn.metrics import f1_score

# Calcular el F1-Score
f1 = f1_score(y_test, y_pred, average='micro')
print(f'F1-Score del modelo: {f1:.2f}')

print(len(y_true))
print(len(y_pred))

y_true = y_true[:len(y_pred)]

from sklearn.metrics import multilabel_confusion_matrix
import matplotlib.pyplot as plt
import numpy as np


# Calcula la matriz de confusión multietiqueta
confusion_matrices = multilabel_confusion_matrix(y_true, y_pred)

# Grafica las matrices de confusión para cada etiqueta
n_classes = confusion_matrices.shape[0]

plt.figure(figsize=(12, 8 * int(np.ceil(n_classes / 2))))
for i in range(n_classes):
    plt.subplot(int(np.ceil(n_classes / 2)), 2, i + 1)
    plt.title(f'Clase {i}')
    sns.heatmap(confusion_matrices[i], annot=True, cmap='Blues', fmt='d', cbar=False)
    plt.xlabel('Etiquetas predichas')
    plt.ylabel('Etiquetas verdaderas')

plt.tight_layout()
plt.show()

"""No pude generar la matriz de confusión, necesito algún feedback para corregir

**API REST**
"""

!pip install Flask

from flask import Flask, jsonify
from flask import request

app = Flask(__name__)

@app.route("/")
def root():
  return 'Home'

if __name__ == '__main__':
  app.run(debug=True)